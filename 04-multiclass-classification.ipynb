{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load the ex3data1\n",
      "# it's in mat format in the course, but can be convert to txt in octave: \n",
      "# save('ex3data1.txt', 'X', '-ascii')\n",
      "# save('ex3data1.y.txt', 'y', '-ascii')\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "def load_dataset():\n",
      "    data = []\n",
      "    y = []    \n",
      "    for line in open('ex3data1.txt'):\n",
      "        data.append(map(double, line.split()))\n",
      "    for line in open('ex3data1.y.txt'):\n",
      "        y.append(int(float(line.strip())))\n",
      "        \n",
      "    return np.array(data, np.double), np.array(y, np.int)\n",
      "    \n",
      "X, y = load_dataset()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.base import BaseEstimator\n",
      "from lbfgs import LBFGS\n",
      "import lbfgs\n",
      "\n",
      "def sigmoid(X, theta):\n",
      "    return 1 / (1 + np.exp(-np.dot(X, theta)))\n",
      "\n",
      "def f(theta, g, lr, X, y):\n",
      "    lr.theta[:] = theta\n",
      "    m = X.shape[0]\n",
      "    predicted = sigmoid(X, theta)\n",
      "    g[:] = fprime(theta, X, y)\n",
      "    return -np.sum(1.0* y * log(predicted) + (1 - y) * log(1 - predicted)) / m\n",
      "\n",
      "def fprime(theta, X, y):\n",
      "    m = X.shape[0]\n",
      "    predicted = sigmoid(X, theta)\n",
      "    error = predicted - y\n",
      "    return np.dot(X.T, error) / m                \n",
      "\n",
      "class LogisticRegression(BaseEstimator):\n",
      "    \n",
      "    def fit(self, X, y):\n",
      "        n = X.shape[1]\n",
      "        x0 = np.zeros(n)\n",
      "        self.theta = np.zeros(n)\n",
      "        opt = LBFGS()\n",
      "        try:\n",
      "            opt.minimize(f, x0, args=[self, X, y])\n",
      "        except Exception, e:\n",
      "            print repr(e)\n",
      "        return self\n",
      "        \n",
      "    def predict_proba(self, X):\n",
      "        positive = sigmoid(X, self.theta).reshape(X.shape[0], 1)\n",
      "        return np.hstack((1-positive, positive))\n",
      "    \n",
      "lr = LogisticRegression()\n",
      "lr.fit(X, y == 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LBFGSError('The line-search routine reaches the maximum number of evaluations.',)\n",
        "CPU times: user 1.12 s, sys: 29.2 ms, total: 1.15 s\n",
        "Wall time: 417 ms\n"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "ovr = OneVsRestClassifier(LogisticRegression())\n",
      "ovr.fit(X, y)\n",
      "print ovr.estimators_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LBFGSError('A rounding error occurred; alternatively, no line-search step satisfies the sufficient decrease and curvature conditions.',)\n",
        "LBFGSError('The line-search routine reaches the maximum number of evaluations.',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LBFGSError('A rounding error occurred; alternatively, no line-search step satisfies the sufficient decrease and curvature conditions.',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LBFGSError('The line-search routine reaches the maximum number of evaluations.',)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[LogisticRegression(), LogisticRegression(), LogisticRegression(), LogisticRegression(), LogisticRegression(), LogisticRegression(), LogisticRegression(), LogisticRegression(), LogisticRegression(), LogisticRegression()]\n",
        "CPU times: user 25 s, sys: 582 ms, total: 25.6 s\n",
        "Wall time: 8.17 s\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
      "predicted = ovr.predict(X)\n",
      "print np.unique(predicted)\n",
      "print 'accuracy', accuracy_score(predicted, y)\n",
      "print confusion_matrix(predicted, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1  2  3  4  5  6  7  8  9 10]\n",
        "accuracy 0.9718\n",
        "[[499   1   1   0   0   0   0   1   0   0]\n",
        " [  1 481   4   1   3   1   1   4   0   0]\n",
        " [  0   1 475   0   3   0   1   7   5   0]\n",
        " [  0   1   0 492   1   0   0   3   3   0]\n",
        " [  0   0   7   0 483   1   0   4   1   0]\n",
        " [  0   0   0   0   1 498   0   1   0   0]\n",
        " [  0   1   5   0   0   0 483   3   9   0]\n",
        " [  0  12   4   2   7   0   3 473   5   1]\n",
        " [  0   1   4   5   2   0  12   3 476   0]\n",
        " [  0   2   0   0   0   0   0   1   1 499]]\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}