{
 "metadata": {
  "name": "04-multiclass-classification"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load the ex3data1\n",
      "# it's in mat format in the course, but can be convert to txt in octave: \n",
      "# save('ex3data1.txt', 'X', '-ascii')\n",
      "# save('ex3data1.y.txt', 'y', '-ascii')\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "data = []\n",
      "for line in open('ex3data1.txt'):\n",
      "    data.append(map(float, line.split()))\n",
      "X = np.array(data, np.float)\n",
      "\n",
      "print X.shape\n",
      "\n",
      "y = []\n",
      "\n",
      "for line in open('ex3data1.y.txt'):\n",
      "    y.append(int(float(line.strip())))\n",
      "y = np.array(y, np.int)\n",
      "\n",
      "print y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5000, 400)\n",
        "(5000,)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.base import BaseEstimator\n",
      "from scipy.optimize import fmin_bfgs\n",
      "\n",
      "def sigmoid(X, theta):\n",
      "    return 1.0 / (1 + e**(-np.dot(X, theta)))\n",
      "\n",
      "class LogisticRegression(BaseEstimator):\n",
      "    \n",
      "    def __init__(self):\n",
      "        self._histories = []\n",
      "        \n",
      "    def fit(self, X, y):\n",
      "                \n",
      "        def f(theta):\n",
      "            m = X.shape[0]        \n",
      "            predicted = sigmoid(X, theta)\n",
      "            return -1 * sum(1.0* y * log(predicted) + (1 - y) * log(1 - predicted)) / m\n",
      "\n",
      "        def fprime(theta):\n",
      "            m = X.shape[0]\n",
      "            predicted = sigmoid(X, theta)\n",
      "            error = predicted - y\n",
      "            return np.dot(X.T, error) / m                \n",
      "        \n",
      "        def callback(theta):\n",
      "            J = f(theta)\n",
      "            self._histories.append(J)\n",
      "\n",
      "        n = X.shape[1]\n",
      "        initial_theta = np.zeros(n)\n",
      "        self.theta = fmin_bfgs(f, initial_theta, fprime=fprime, callback=callback)\n",
      "        return self\n",
      "        \n",
      "    def predict_proba(self, X):\n",
      "        return sigmoid(X, self.theta)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'LogisticRegression' object has no attribute 'theta'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-38-d3180f2f7c59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'theta'"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "import time\n",
      "\n",
      "base_estimator = LogisticRegression()\n",
      "ovr = OneVsRestClassifier(base_estimator)\n",
      "t0 = time.time()\n",
      "ovr.fit(X, y)\n",
      "t1 = time.time()\n",
      "print t1-t0, 'seconds to fit'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warning: Desired error not necessarily achieved due to precision loss.\n",
        "         Current function value: nan\n",
        "         Iterations: 135\n",
        "         Function evaluations: 148\n",
        "         Gradient evaluations: 148\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: nan\n",
        "         Iterations: 462\n",
        "         Function evaluations: 474\n",
        "         Gradient evaluations: 474\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: nan\n",
        "         Iterations: 1274\n",
        "         Function evaluations: 1287\n",
        "         Gradient evaluations: 1287\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: nan\n",
        "         Iterations: 263\n",
        "         Function evaluations: 277\n",
        "         Gradient evaluations: 277\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: nan\n",
        "         Iterations: 501\n",
        "         Function evaluations: 517\n",
        "         Gradient evaluations: 517\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: nan\n",
        "         Iterations: 154\n",
        "         Function evaluations: 168\n",
        "         Gradient evaluations: 168\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: nan\n",
        "         Iterations: 168\n",
        "         Function evaluations: 182\n",
        "         Gradient evaluations: 182\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.100449\n",
        "         Iterations: 1925\n",
        "         Function evaluations: 1927\n",
        "         Gradient evaluations: 1927\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 0.062133\n",
        "         Iterations: 1928\n",
        "         Function evaluations: 1932\n",
        "         Gradient evaluations: 1932\n",
        "Warning: Desired error not necessarily achieved due to precision loss."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: nan\n",
        "         Iterations: 130\n",
        "         Function evaluations: 146\n",
        "         Gradient evaluations: 146\n",
        "172.827217817 seconds to fit\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
      "print dir(ovr.estimator)\n",
      "predicted = ovr.estimator.predict_proba(X)\n",
      "\n",
      "#print 'accuracy', accuracy_score(predicted, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'LogisticRegression' object has no attribute 'theta'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-37-680cef968a02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0movr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0movr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print 'accuracy', accuracy_score(predicted, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-31-7fc1a1a0500d>\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'theta'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_param_names', '_histories', 'fit', 'get_params', 'predict_proba', 'set_params']\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}